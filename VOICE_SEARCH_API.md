# Voice Search & Translation API Documentation

## üéØ Overview

Production-grade multilingual voice search system for recipe discovery. Supports 11 Indian languages with end-to-end AI pipeline integration.

---

## üì° API Endpoints

### 1. Speech-to-Text (STT)

**POST** `/stt`

Convert audio recordings to text using OpenAI Whisper model.

#### Supported Languages
- **English** (en)
- **Hindi** (hi) - ‡§π‡§ø‡§Ç‡§¶‡•Ä
- **Bengali** (bn) - ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ
- **Telugu** (te) - ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å
- **Marathi** (mr) - ‡§Æ‡§∞‡§æ‡§†‡•Ä
- **Tamil** (ta) - ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç
- **Gujarati** (gu) - ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä
- **Kannada** (kn) - ‡≤ï‡≤®‡≥ç‡≤®‡≤°
- **Malayalam** (ml) - ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç
- **Odia** (or) - ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü
- **Punjabi** (pa) - ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä

#### Audio Requirements
- **Formats**: webm, wav, mp3, ogg, m4a
- **Max Size**: 25MB
- **Encoding**: Base64

#### Request
```json
{
  "audio": "UklGRiQAAABXQVZFZm10IBAAAAABAAEA...",
  "format": "webm"
}
```

#### Response
```json
{
  "transcript": "‡§Æ‡•Å‡§ù‡•á ‡§™‡§®‡•Ä‡§∞ ‡§ü‡§ø‡§ï‡•ç‡§ï‡§æ ‡§ï‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è",
  "confidence": 0.95,
  "detectedLanguage": "hi"
}
```

#### Error Codes
- `400 Bad Request`: Invalid audio data, empty audio, or file too large
- `503 Service Unavailable`: Whisper model not loaded
- `500 Internal Server Error`: Transcription failed

---

### 2. Translation

**POST** `/translate`

Translate text between English and Indian languages with culinary term preservation.

#### Features
- **Auto Language Detection**: Set `sourceLang: "auto"`
- **Bidirectional**: Any language ‚Üî English
- **Culinary Terms**: Preserves food-specific terminology (paneer, dal, biryani, etc.)

#### Request
```json
{
  "text": "‡§Æ‡•Å‡§ù‡•á ‡§™‡§®‡•Ä‡§∞ ‡§ü‡§ø‡§ï‡•ç‡§ï‡§æ ‡§ï‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è",
  "sourceLang": "auto",
  "targetLang": "en"
}
```

#### Response
```json
{
  "translatedText": "I want paneer tikka recipe",
  "detectedSourceLang": "hi",
  "confidence": 0.92
}
```

#### Culinary Term Preservation
The system maintains accurate translations for:
- **Ingredients**: paneer, dal, ghee, atta, besan
- **Dishes**: biryani, tikka, korma, samosa
- **Techniques**: tadka, dum, tandoor

---

### 3. Voice Search (Complete Pipeline)

**POST** `/voice-search`

End-to-end voice search combining STT ‚Üí Translation ‚Üí NLP ‚Üí Recipe Search.

#### Pipeline Flow
```
Audio Input
    ‚Üì [Whisper STT]
Native Language Text (e.g., Hindi)
    ‚Üì [Translation]
English Text
    ‚Üì [NLP Parser]
Structured Constraints
    ‚Üì [Recipe Search]
Matching Recipes
```

#### Request
```json
{
  "audio": "UklGRiQAAABXQVZFZm10IBAAAAABAAEA...",
  "format": "webm"
}
```

#### Response
Same as `/search` endpoint, with additional metadata:
```json
{
  "results": [...],
  "query": {
    "text": "I want paneer tikka recipe under 30 minutes",
    "lang": "en",
    "constraints": {
      "include": ["paneer", "tikka"],
      "maxCookMinutes": 30
    }
  },
  "translatedQuery": "‡§Æ‡•Å‡§ù‡•á 30 ‡§Æ‡§ø‡§®‡§ü ‡§Æ‡•á‡§Ç ‡§™‡§®‡•Ä‡§∞ ‡§ü‡§ø‡§ï‡•ç‡§ï‡§æ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è",
  "count": 12,
  "durationMs": 3420.5
}
```

#### Performance
- **STT**: ~500-1500ms (depends on audio length)
- **Translation**: ~50-200ms
- **NLP Parsing**: ~5-20ms
- **Search**: ~100-500ms
- **Total**: ~700-2200ms typical

---

## üîß Technical Implementation

### Whisper Model Configuration

```python
# Default: base model (74M params)
# Available models: tiny, base, small, medium, large
model = whisper.load_model("base")

# Auto language detection
result = model.transcribe(
    audio_path,
    language=None,  # Auto-detect
    task='transcribe'
)
```

### Translation Strategy

1. **Script Detection**: Identify language by Unicode range
2. **Culinary Terms**: Apply food-specific translation table
3. **Fallback**: Return original text if translation fails

### Error Handling

All endpoints include:
- ‚úÖ Input validation with detailed error messages
- ‚úÖ Graceful degradation (translation failures don't break search)
- ‚úÖ Structured logging for debugging
- ‚úÖ Retry logic for transient failures

---

## üìä Usage Examples

### Example 1: Hindi Voice Search
```bash
# User speaks: "‡§Æ‡•Å‡§ù‡•á ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§¨‡§®‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§™‡§®‡•Ä‡§∞ ‡§ï‡•Ä ‡§∞‡•á‡§∏‡§ø‡§™‡•Ä ‡§¨‡§§‡§æ‡§ì"
# (Give me quick paneer recipes)

POST /voice-search
{
  "audio": "<base64_audio>",
  "format": "webm"
}

# Response:
# - Detected: Hindi
# - Translated: "give me quick paneer recipes"
# - Parsed: include=[paneer], maxCookMinutes=30
# - Results: 15 paneer recipes under 30 minutes
```

### Example 2: Bengali Voice Search
```bash
# User speaks: "‡¶Ü‡¶Æ‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶∞‡ßá‡¶∏‡¶ø‡¶™‡¶ø ‡¶ö‡¶æ‡¶á ‡¶Æ‡¶∂‡¶≤‡¶æ ‡¶õ‡¶æ‡¶°‡¶º‡¶æ"
# (I want fish recipe without spices)

POST /voice-search
{
  "audio": "<base64_audio>",
  "format": "webm"
}

# Response:
# - Detected: Bengali
# - Translated: "I want fish recipe without spices"
# - Parsed: include=[fish], exclude=[spices]
# - Results: Mild fish recipes
```

### Example 3: Tamil Vegetarian Search
```bash
# User speaks: "‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ ‡Æö‡Øà‡Æµ ‡Æâ‡Æ£‡Æµ‡ØÅ ‡Æö‡ÆÆ‡Øà‡ÆØ‡Æ≤‡Øç ‡Æï‡ØÅ‡Æ±‡Æø‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç"
# (I want vegetarian food recipes)

POST /voice-search
{
  "audio": "<base64_audio>",
  "format": "webm"
}

# Response:
# - Detected: Tamil
# - Translated: "I want vegetarian food recipes"
# - Parsed: diet=[Vegetarian]
# - Results: 200+ vegetarian recipes
```

---

## üöÄ Frontend Integration

### 1. Record Audio
```typescript
const mediaRecorder = new MediaRecorder(stream, {
  mimeType: 'audio/webm'
});

const chunks: Blob[] = [];
mediaRecorder.ondataavailable = (e) => chunks.push(e.data);

mediaRecorder.onstop = async () => {
  const audioBlob = new Blob(chunks, { type: 'audio/webm' });
  const base64Audio = await blobToBase64(audioBlob);
  
  // Call voice search API
  const response = await fetch('/api/voice-search', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      audio: base64Audio,
      format: 'webm'
    })
  });
  
  const results = await response.json();
  displayRecipes(results);
};
```

### 2. Display Transcription
```typescript
// Show what user said
<div className="transcription">
  <p className="original">"{data.translatedQuery}"</p>
  <p className="translated">‚Üí "{data.query.text}"</p>
</div>
```

### 3. Show Detected Constraints
```typescript
// Visual pills for detected constraints
{data.query.constraints?.diet && (
  <Badge variant="success">
    <Leaf className="w-3 h-3" />
    {data.query.constraints.diet.join(', ')}
  </Badge>
)}

{data.query.constraints?.maxCookMinutes && (
  <Badge variant="info">
    <Clock className="w-3 h-3" />
    Under {data.query.constraints.maxCookMinutes}min
  </Badge>
)}
```

---

## üîí Security & Privacy

### Audio Data
- ‚úÖ **Not stored**: Audio is transcribed and immediately discarded
- ‚úÖ **In-memory processing**: Temporary files deleted after use
- ‚úÖ **Size limits**: 25MB max to prevent abuse

### API Rate Limiting
- ‚ö†Ô∏è **TODO**: Implement rate limiting (100 requests/minute/IP)
- ‚ö†Ô∏è **TODO**: Add API key authentication for production

---

## üìà Monitoring & Logging

All endpoints log structured data:

```json
{
  "event": "voice_search_complete",
  "total_duration_ms": 2150.5,
  "stt_ms": 1420.3,
  "translation_ms": 85.2,
  "nlp_ms": 12.8,
  "search_ms": 632.2,
  "results_count": 15,
  "original_language": "hi",
  "translated": true
}
```

### Key Metrics to Monitor
1. **STT Latency**: Should be < 2000ms
2. **Translation Accuracy**: Monitor user feedback
3. **NLP Confidence**: Track average confidence scores
4. **Error Rates**: < 1% transcription failures
5. **Language Distribution**: Track which languages users speak

---

## üêõ Troubleshooting

### Issue: "Whisper model not loaded"
**Solution**: 
```bash
pip install openai-whisper
# Model downloads automatically on first use (~140MB for base)
```

### Issue: "Audio transcription failed"
**Causes**:
- Corrupted audio file
- Unsupported format
- Audio too long (>25MB)

**Solution**: Check audio format and size

### Issue: "Translation service unavailable"
**Behavior**: System gracefully degrades, uses original text for search

**Solution**: Check translation_adapter initialization in logs

---

## üéì Best Practices

1. **Microphone Quality**: Use noise-cancelling microphones for better accuracy
2. **Audio Duration**: Keep recordings under 30 seconds for best results
3. **Language Consistency**: Let Whisper auto-detect language instead of forcing
4. **Error Handling**: Always show user-friendly messages on failures
5. **Loading States**: Show visual feedback during processing (2-3 seconds)

---

## üìù Next Steps

- [ ] Add caching for repeated phrases
- [ ] Implement real-time streaming transcription
- [ ] Support code-mixed queries (Hinglish: "paneer recipes under 30 min")
- [ ] Add pronunciation variations handling
- [ ] Implement confidence-based retry prompts

---

*Last Updated: November 11, 2025*
*Backend Version: 1.0.0*
*Whisper Model: base (multilingual)*
